{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QoutiOussama13/AI-EarthHack-MOAA-/blob/main/Idea_Evaluator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some notes :\n",
        "\n",
        "*   Ensure the you are using google collab to run this notebook with Hardware accelertor set as **GPU**\n",
        "\n",
        "*   Some cells may take some time to run if you have **Colab Pro** that would fix the problem\n",
        "\n",
        "*   make sure to replace the ```./path_to_data``` with the real path of the data folder *preferebly on Google drive*\n",
        "\n",
        "* Enjoy ðŸ˜€!\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "erdKzYat0WOQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **requirements**"
      ],
      "metadata": {
        "id": "j0L2PHcmqsXA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IqEfXblTKW3"
      },
      "outputs": [],
      "source": [
        "!pip install langchain sentence-transformers chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVOJVecRQ86U"
      },
      "outputs": [],
      "source": [
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US8hhnx6H8Nj"
      },
      "source": [
        "# **Improting the libreries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yR77aLdtMWEA"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain import PromptTemplate\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from huggingface_hub import InferenceClient\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA,ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from huggingface_hub import hf_hub_download\n",
        "from langchain.llms import LlamaCpp\n",
        "import time\n",
        "from langchain.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this is to connect with google drive"
      ],
      "metadata": {
        "id": "zcrc0BHnr6a5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaqeqncSEkHy",
        "outputId": "36fcd6cd-2bf6-460c-fac0-8dbff0bb4961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "DkVEzPnQSfqH"
      },
      "outputs": [],
      "source": [
        "loader = DirectoryLoader('./path_to_data', glob=\"**/*.txt\", loader_cls=TextLoader)\n",
        "pages = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "nIT8v9_8SpI5"
      },
      "outputs": [],
      "source": [
        "def split_text(documents: list[Document]):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=150,\n",
        "        length_function=len,\n",
        "        add_start_index=True,\n",
        "    )\n",
        "    chunks = text_splitter.split_documents(documents)\n",
        "    print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
        "\n",
        "    document = chunks[10]\n",
        "    print(document.page_content)\n",
        "    print(document.metadata)\n",
        "\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTjtx6YQTK6f",
        "outputId": "f8b76151-3827-4829-ff0c-e3e01ee2281e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split 10 documents into 372 chunks.\n",
            "Does this mean that the whole organisation sells the same thing the same way, year after year? No - solution repeatability also involves the ability to sense, react and adapt to changing market conditions.\n",
            "Look at the list on the right. Where would you place your organisation?\n",
            "    REPEATABILITY OF SOLUTIONS\n",
            "  UNSCALABLE\n",
            "    1: Random\n",
            "Your solutions are created from scratch to address unique customer needs, with little standardisation. Every sale seems hand-crafted.\n",
            "    2: Common Components\n",
            "You have created a family of common components from which you build solutions, but sales still often have somewhat unique elements to them.\n",
            "    3: Standardised\n",
            "You have established standardised product or service offerings that you are marketing & selling in a reasonably consistent fashion.\n",
            "    4: Replicable\n",
            "The majority of your revenues come from clearly defined, standardised product and service offerings sold in a repeatable, consistent way.\n",
            "    5: Highly Repeatable\n",
            "{'source': '/content/drive/MyDrive/EarthHack/EarthHack/Data/Asma/scalibility_hubspot.txt', 'start_index': 7302}\n"
          ]
        }
      ],
      "source": [
        "chunks_text = split_text(pages)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The embedding model\n",
        "[e5-small-v](https://huggingface.co/intfloat/e5-small-v2)"
      ],
      "metadata": {
        "id": "-_aDOUvksR-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = HuggingFaceEmbeddings(model_name='intfloat/e5-small-v2')"
      ],
      "metadata": {
        "id": "GIsyQJVwrXdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "saving the data we have in the vector database [ChromaDB](https://https://www.trychroma.com)"
      ],
      "metadata": {
        "id": "erIAU7Sls4Kc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "s8Sc_hyUZaIj"
      },
      "outputs": [],
      "source": [
        "db = Chroma.from_documents(chunks_text, embedding=embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "initializing the [LLM](https://huggingface.co/TheBloke/Mistral-7B-OpenOrca-GGUF) we are going to work with  "
      ],
      "metadata": {
        "id": "zfP8y-yRtO4x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ODVh7NM3fbtu"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"TheBloke/Mistral-7B-OpenOrca-GGUF\"\n",
        "MODEL_BASENAME = \"mistral-7b-openorca.Q4_K_M.gguf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QvIpSRPJZaT7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "310d72418e024569be15e750a02441ae",
            "1514a1543d0e4be7911cdb3d4100e89c",
            "3628a350d1074b6aab8a628abb41e378",
            "87a055df299a423eb8bd5cb938bad83c",
            "cc3914240d4b4890b58f205bd6b28d4b",
            "9238e26cd5744739a61be50f23aa8502",
            "8d195dda5de64973a8ddccf3b5cfcd42",
            "fc8e00691d0e453091fcf57a928dbd65",
            "c801572277b544169ecf040cb95b4e1c",
            "6e8552da452f40a3ae8ccac29fbc9fbf",
            "dc7ae98df930409ab393aad974e3513f"
          ]
        },
        "outputId": "960a9849-3390-4771-d191-f767092c29eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "mistral-7b-openorca.Q4_K_M.gguf:   0%|          | 0.00/4.37G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "310d72418e024569be15e750a02441ae"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_path = hf_hub_download(\n",
        "            repo_id=MODEL_ID,\n",
        "            filename=MODEL_BASENAME,\n",
        "            resume_download=True,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "smEXLb_-Zaae"
      },
      "outputs": [],
      "source": [
        "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
        "\n",
        "CONTEXT_WINDOW_SIZE = 1900\n",
        "MAX_NEW_TOKENS = 2500\n",
        "N_BATCH = 1\n",
        "n_gpu_layers = 40\n",
        "kwargs = {\n",
        "          \"model_path\": model_path,\n",
        "          \"n_ctx\": CONTEXT_WINDOW_SIZE,\n",
        "          \"max_tokens\": MAX_NEW_TOKENS,\n",
        "          \"n_batch\": N_BATCH,\n",
        "          \"n_gpu_layers\": n_gpu_layers,\n",
        "          \"callback_manager\": callback_manager,\n",
        "          \"verbose\":True,\n",
        "      }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instance creation using [LlamaCpp](https://github.com/ggerganov/llama.cpp)"
      ],
      "metadata": {
        "id": "PDTi5ItNuJwR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkOykDCnZad7",
        "outputId": "e94e3fde-007b-44bb-c76c-a60f43e5d19b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ],
      "source": [
        "llm = LlamaCpp(**kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing some examples to see the performance of the model"
      ],
      "metadata": {
        "id": "JjtIrS8bud8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = \"hey how are you?\"\n",
        "business_idea = \"\"\"\n",
        "My proposal is to establish an intuitive, user-friendly digital sharing platform named 'WasteNot'. This platform will revolutionize waste management by serving as a bridge that connects waste-generating companies with businesses seeking these materials for reuse or recycling. It supports the circular economy by extending the life of materials and reducing the need for fresh raw material extraction. Furthermore, it benefits businesses financially by means of lowered waste disposal costs for waste generators and reduced raw material procurement expenses for recycling companies. The platform is easy to implement through web and mobile-based applications, and it is scalable to cater to businesses of varying sizes across different industries, thus promoting a more sustainable global business environment.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "dbykGyS92iuN"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "DK4S75O3uQsF"
      },
      "outputs": [],
      "source": [
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=db.as_retriever(search_kwargs={\"k\": 5}),\n",
        "    return_source_documents=True,\n",
        "    verbose=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a template for the model to ensure it responds according to our specifications."
      ],
      "metadata": {
        "id": "-ot-0mzrusj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_template = \"\"\"\n",
        "You are and expert idea validator in terms of circular economy principles to address climate change.\n",
        "Carefully evaluate the provided business idea based on six key metricsâ€” circular economy (which include resource efficiency, waste management, long term viability, closed loop system, life cycle analysis), feasibility, scalability, innovation, and social impact and generate a score (0 to 10) for each metric, avoiding assumptions.\n",
        "Ensure the evaluation is grounded in the context's content, avoiding assumptions.\n",
        "Provide a comprehensive score and insights for each metric to guide investors in aligning their ambitions with the most promising business opportunities.\n",
        "Add at the end the overall score for the evalution .\n",
        "remember you don't read any buisness idea from the context , your only interest is the buisness idea provided by the user\n",
        "If the user provided something other than a business idea  , just say that you cannot answer politly in just few words , don't try to make up an answer from something in the context.\n",
        "Context: {context}\n",
        "Business Idea: {question}\n",
        "your answer with the evaluation and the short description for each metric and ways of improving the business idea :  \"\"\"\n",
        "\n",
        "\n",
        "NEW_PROMPT = PromptTemplate(template=new_template, input_variables=['context', 'question'])"
      ],
      "metadata": {
        "id": "Q-pw-NMAJOCJ"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa.combine_documents_chain.llm_chain.prompt = NEW_PROMPT"
      ],
      "metadata": {
        "id": "x0xnm2MDKNTG"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## running the tests:\n",
        "\n",
        "*Note :the results may change even using the same prompt , we suggest that experiment with different prompts multiple times*"
      ],
      "metadata": {
        "id": "pqUVqHZCxd1V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "first test"
      ],
      "metadata": {
        "id": "Pm8RWisgyovx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res_1 = qa(business_idea)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "823466d2-ce16-4de9-845b-a4764672f5d4",
        "id": "WbKn6wrL2_61"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. Circular Economy: 8/10 (Resource efficiency, waste management, long term viability, closed loop system, life cycle analysis)\n",
            "The business idea presents a model that leverages the principles of microscale mechanics to create energy-efficient cooling systems. It promotes resource efficiency and waste reduction by extending the life of chillers, reducing energy consumption, and minimizing environmental impacts. A closed-loop system is created through the minimal electrical requirements, and life cycle analysis can identify areas for improvement. However, it could be improved by further research on materials used in chillers and exploring opportunities for recycling or repurposing these materials at the end of their life cycles.\n",
            "\n",
            "2. Feasibility: 8/10\n",
            "The business idea appears to be feasible, as it relies on proven scientific principles and existing technologies. However, further research and development are needed to refine the model and ensure its scalability. This includes optimizing the design and materials used in the chillers to achieve maximum energy efficiency and cost savings.\n",
            "\n",
            "3. Scalability: 7/10\n",
            "The business idea has a potential for scalability across various industries, such as refrigeration, HVAC systems, and industrial cooling processes. However, challenges may arise due to the need for specialized manufacturing techniques or materials. Additionally, market acceptance and regulatory approvals will play crucial roles in determining the success of this solution on a large scale.\n",
            "\n",
            "4. Innovation: 9/10\n",
            "The proposed model offers an innovative approach to energy efficiency by leveraging microscale mechanics and superconductivity principles. This concept could potentially disrupt traditional cooling solutions, which often rely on high electricity consumption or chemical refrigerants that have significant environmental impacts. Continuous innovation in materials science and optimization of the geometric model can further enhance its performance and market potential.\n",
            "\n",
            "5. Social Impact: 8/10\n",
            "The business idea aims to address climate change by reducing energy waste and minimizing business costs through resource efficiency and waste reduction. By implementing this solution, businesses can cut down on their carbon footprint, contribute to the circular economy principles, and promote sustainable development. However, social impact could be further improved by considering local job creation, economic opportunities, and community education about the benefits of this technology.\n",
            "\n",
            "Overall Score: 8.4/10"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Business Idea :\")\n",
        "print (business_idea)\n",
        "print(\"LLM response :\")\n",
        "print(res_1['result'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tR7nxsSwDPt",
        "outputId": "deb60b7d-5812-4b92-ed78-0bc2784602a5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "Business Idea :\n",
            "My proposal is to establish an intuitive, user-friendly digital sharing platform named 'WasteNot'. \n",
            "This platform will revolutionize waste management by serving as a bridge that connects waste-generating companies with businesses seeking these materials for reuse or recycling.\n",
            "It supports the circular economy by extending the life of materials and reducing the need for fresh raw material extraction.\n",
            "Furthermore, it benefits businesses financially by means of lowered waste disposal costs for waste generators and reduced raw material procurement expenses for recycling companies. \n",
            "The platform is easy to implement through web and mobile-based applications, and it is scalable to cater to businesses of varying sizes across different industries, thus promoting a more sustainable global business environment.\n",
            "\n",
            "LLM response : \n",
            "1. Circular Economy: 8/10 (Resource efficiency, waste management, long term viability, closed loop system, life cycle analysis)\n",
            "The business idea presents a model that leverages the principles of microscale mechanics to create energy-efficient cooling systems. It promotes resource efficiency and waste reduction by extending the life of chillers, reducing energy consumption, and minimizing environmental impacts. A closed-loop system is created through the minimal electrical requirements, and life cycle analysis can identify areas for improvement. However, it could be improved by further research on materials used in chillers and exploring opportunities for recycling or repurposing these materials at the end of their life cycles.\n",
            "\n",
            "2. Feasibility: 8/10\n",
            "The business idea appears to be feasible, as it relies on proven scientific principles and existing technologies. However, further research and development are needed to refine the model and ensure its scalability. This includes optimizing the design and materials used in the chillers to achieve maximum energy efficiency and cost savings.\n",
            "\n",
            "3. Scalability: 7/10\n",
            "The business idea has a potential for scalability across various industries, such as refrigeration, HVAC systems, and industrial cooling processes. However, challenges may arise due to the need for specialized manufacturing techniques or materials. Additionally, market acceptance and regulatory approvals will play crucial roles in determining the success of this solution on a large scale.\n",
            "\n",
            "4. Innovation: 9/10\n",
            "The proposed model offers an innovative approach to energy efficiency by leveraging microscale mechanics and superconductivity principles. This concept could potentially disrupt traditional cooling solutions, which often rely on high electricity consumption or chemical refrigerants that have significant environmental impacts. Continuous innovation in materials science and optimization of the geometric model can further enhance its performance and market potential.\n",
            "\n",
            "5. Social Impact: 8/10\n",
            "The business idea aims to address climate change by reducing energy waste and minimizing business costs through resource efficiency and waste reduction. By implementing this solution, businesses can cut down on their carbon footprint, contribute to the circular economy principles, and promote sustainable development. However, social impact could be further improved by considering local job creation, economic opportunities, and community education about the benefits of this technology.\n",
            "\n",
            "Overall Score: 8.4/10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "second test"
      ],
      "metadata": {
        "id": "fg5dJmQjyrUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res_2 = qa(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTnfwnV1yEOf",
        "outputId": "9d845fe9-22fd-46bd-915a-80d7343b28ff"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Your buisness idea is not provided. Please provide a business idea for me to evaluate. If you need an evaluation, please ask in the context."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"testing to see if it will responde to a random prompt :\")\n",
        "print (test)\n",
        "print(\"LLM response :\")\n",
        "print(res_2['result'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3Chod1RzBeg",
        "outputId": "26e450b6-f414-4176-e4ee-5e0a26d96c53"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing to see if it will responde to a random prompt :\n",
            "hey how are you?\n",
            "LLM response :\n",
            "Your buisness idea is not provided. Please provide a business idea for me to evaluate. If you need an evaluation, please ask in the context.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you have any question/issue with running the code please feel free to reach out to [Oussama](https://https://www.linkedin.com/in/oussama-qouti-105bb820a/)"
      ],
      "metadata": {
        "id": "rgVceAhIz5oN"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "310d72418e024569be15e750a02441ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1514a1543d0e4be7911cdb3d4100e89c",
              "IPY_MODEL_3628a350d1074b6aab8a628abb41e378",
              "IPY_MODEL_87a055df299a423eb8bd5cb938bad83c"
            ],
            "layout": "IPY_MODEL_cc3914240d4b4890b58f205bd6b28d4b"
          }
        },
        "1514a1543d0e4be7911cdb3d4100e89c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9238e26cd5744739a61be50f23aa8502",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8d195dda5de64973a8ddccf3b5cfcd42",
            "value": "mistral-7b-openorca.Q4_K_M.gguf: 100%"
          }
        },
        "3628a350d1074b6aab8a628abb41e378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc8e00691d0e453091fcf57a928dbd65",
            "max": 4368450304,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c801572277b544169ecf040cb95b4e1c",
            "value": 4368450304
          }
        },
        "87a055df299a423eb8bd5cb938bad83c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e8552da452f40a3ae8ccac29fbc9fbf",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_dc7ae98df930409ab393aad974e3513f",
            "value": " 4.37G/4.37G [00:34&lt;00:00, 164MB/s]"
          }
        },
        "cc3914240d4b4890b58f205bd6b28d4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9238e26cd5744739a61be50f23aa8502": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d195dda5de64973a8ddccf3b5cfcd42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc8e00691d0e453091fcf57a928dbd65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c801572277b544169ecf040cb95b4e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e8552da452f40a3ae8ccac29fbc9fbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc7ae98df930409ab393aad974e3513f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}